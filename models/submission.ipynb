{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     21,
     43
    ]
   },
   "outputs": [],
   "source": [
    "import logging, os, json, glob, h5py, pickle, math, collections\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Tuple, Union, Any\n",
    "\n",
    "def load_h5_file(file_path: Union[str, Path], sl: Optional[slice] = None, to_torch: bool = False) -> np.ndarray:\n",
    "    \"\"\"Given a file path to an h5 file assumed to house a tensor, load that\n",
    "    tensor into memory and return a pointer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path: str\n",
    "        h5 file to load\n",
    "    sl: Optional[slice]\n",
    "        slice to load (data is written in chunks for faster access to rows).\n",
    "    \"\"\"\n",
    "    # load\n",
    "    with h5py.File(str(file_path) if isinstance(file_path, Path) else file_path, \"r\") as fr:\n",
    "        data = fr.get(\"array\")\n",
    "        if sl is not None:\n",
    "            data = np.array(data[sl])\n",
    "        else:\n",
    "            data = np.array(data)\n",
    "        if to_torch:\n",
    "            data = torch.from_numpy(data)\n",
    "            data = data.to(dtype=torch.float)\n",
    "        return data\n",
    "def write_data_to_h5(data: np.ndarray, filename: Union[str, Path], compression=\"gzip\", compression_level=9, dtype=\"uint8\", verbose=True):\n",
    "    \"\"\"write data in gzipped h5 format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "    filename\n",
    "    compression\n",
    "    compression_level\n",
    "    verbose\n",
    "    \"\"\"\n",
    "    with h5py.File(filename if isinstance(filename, str) else str(filename), \"w\", libver=\"latest\") as f:\n",
    "        if data.dtype != dtype:\n",
    "            logging.warning(f\"Found data with {data.dtype}, expected {dtype}.\")\n",
    "        if verbose:\n",
    "            print(f\"writing {filename} ...\")\n",
    "        f.create_dataset(\n",
    "            # `chunks=(1, *data.shape[1:])`: optimize for row access!\n",
    "            \"array\",\n",
    "            shape=data.shape,\n",
    "            data=data,\n",
    "            chunks=(1, *data.shape[1:]),\n",
    "            dtype=dtype,\n",
    "            compression=compression,\n",
    "            compression_opts=compression_level,\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"... done writing {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make some prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cpu'\n",
    "class Runner():\n",
    "    def __init__(self, model_name='Resnet3D'):\n",
    "        self.model_name = model_name\n",
    "        self.model = globals()[model_name]()\n",
    "        # if torch.cuda.device_count() > 1:\n",
    "            # self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.to(device)\n",
    "    def predict(self, checkpoint_dir='./checkpoints/Resnet3D.pk', mode='core', use_mask=True):\n",
    "        \n",
    "        submission_name = f'submission_{self.model_name}'\n",
    "        \n",
    "        model_dic = torch.load(checkpoint_dir)\n",
    "        new_state_dict = collections.OrderedDict() \n",
    "        for k, v in model_dic.items(): \n",
    "            name = k.replace('module.', '')# remove `module.` \n",
    "            new_state_dict[name] = v\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "        self.model.eval()\n",
    "        \n",
    "        if mode =='core':\n",
    "            cities = ['BERLIN', 'CHICAGO', 'ISTANBUL', 'MELBOURNE']\n",
    "            postfix = 'temporal'\n",
    "        else:\n",
    "            cities = ['VIENNA', 'NEWYORK']\n",
    "            postfix = 'spatiotemporal'\n",
    "            \n",
    "        for city in cities:\n",
    "            print(f'Predicting {city}...')\n",
    "            # read city information\n",
    "            with h5py.File(f'../data/raw/{city}/{city}_test_{postfix}.h5', \"r\") as f:\n",
    "                test_data = f.get(\"array\")\n",
    "                test_data = np.array(test_data)\n",
    "            # MASK\n",
    "            if use_mask:\n",
    "                mask = np.zeros([495, 436, 8])\n",
    "                for n in range(100):\n",
    "                    for t in range(12):\n",
    "                        mask = np.logical_or(mask, test_data[n, t, :, :, :])\n",
    "                mask = torch.from_numpy(mask).to(device)\n",
    "\n",
    "            y_preds = []\n",
    "            for x in tqdm.tqdm(test_data):\n",
    "                x = torch.from_numpy(x).unsqueeze(0).float().to(device)\n",
    "                if use_mask:\n",
    "                    y_pred = self.model(x) * mask\n",
    "                else:\n",
    "                    y_pred = self.model(x)\n",
    "                y_pred[y_pred < 1] = 0\n",
    "                y_pred[y_pred > 255] = 255\n",
    "                y_preds.append(y_pred.cpu().detach().numpy())\n",
    "                torch.cuda.empty_cache()\n",
    "            y_preds = np.concatenate(y_preds, axis=0)\n",
    "\n",
    "            Path(f'{submission_name}/{city}/').mkdir(parents=True, exist_ok=True)\n",
    "            write_data_to_h5(y_preds.astype(np.uint8), f'{submission_name}/{city}/{city}_test_{postfix}.h5')\n",
    "            print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     27,
     50,
     62
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model 1 - Resnet3D\n",
    "inlen, outlen = 12, 6\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.cnn = nn.Conv3d(12, 12, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, [1, 12, 495, 436, 8]\n",
    "        \"\"\"\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0,2,3,1,4)\n",
    "        pe = self.pe[:12].squeeze()\n",
    "        #print(x.shape, pe.shape)\n",
    "        x = x + pe\n",
    "        x = x.permute(0,3,1,2,4)\n",
    "        #print(x.shape)\n",
    "        return self.dropout(x) \n",
    "class Resnet3DBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=4, leakyrate=0.2):\n",
    "        super(Resnet3DBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(hidden_size, hidden_size, kernel_size=(1,3,3), stride=(1,1,1), padding=(0,1,1))\n",
    "        #self.conv2 = nn.Conv3d(hidden_size, hidden_size, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1), bias=False)\n",
    "        #self.bn = nn.BatchNorm3d(hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm((8, 495, 436))\n",
    "        #self.relu = nn.ReLU()\n",
    "        self.relu = nn.LeakyReLU(leakyrate)\n",
    "        #self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer_norm(out)\n",
    "        out = self.relu(out)\n",
    "        #out = self.dropout(out)\n",
    "\n",
    "        out = (out + identity)\n",
    "\n",
    "        return out\n",
    "class InceptionIn(nn.Module):\n",
    "    def __init__(self, hidden_size=24):\n",
    "        super(InceptionIn, self).__init__()\n",
    "        self.cnn1x1 = nn.Conv3d(inlen, hidden_size, kernel_size=(1,1,1), stride=(1,1,1), padding=(0,0,0))\n",
    "        self.cnn3x3 = nn.Conv3d(inlen, hidden_size, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1))\n",
    "        # self.cnn7x7 = nn.Conv3d(inlen, hidden_size, kernel_size=(3,7,7), stride=(1,1,1), padding=(1,3,3))\n",
    "    def forward(self, x):\n",
    "        out1 = self.cnn1x1(x)\n",
    "        out2 = self.cnn3x3(x)\n",
    "        # out3 = self.cnn7x7(x)\n",
    "        out = out1 + out2 # + out3\n",
    "        return out\n",
    "class Resnet3D(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers=4, hidden_size=16, leakyrate=0.2):\n",
    "        super(Resnet3D, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.pe = PositionalEncoding(8)\n",
    "        self.relu = nn.LeakyReLU(leakyrate)\n",
    "        #self.relu = nn.ReLU()\n",
    "        #self.cnn_in = nn.Conv3d(inlen, hidden_size, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1), bias=True)\n",
    "        self.cnn_in = InceptionIn(hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm((8, 495, 436))\n",
    "        # self.bn = nn.BatchNorm3d(hidden_size)\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            setattr(self, f'resnet{i}', Resnet3DBlock(hidden_size, leakyrate))\n",
    "        self.cnn_out = nn.Conv3d(hidden_size, outlen, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1))\n",
    "\n",
    "        # init\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Conv3d)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm, nn.BatchNorm3d)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # positional encoding\n",
    "        x = self.pe(x)\n",
    "        \n",
    "        x = rearrange(x, 'b t w h c -> b t c w h')\n",
    "       \n",
    "        # print('input shape is ', x.shape)\n",
    "        x = self.layer_norm(self.relu(self.cnn_in(x)))\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            x = getattr(self, f'resnet{i}')(x)\n",
    "\n",
    "        #print(\"out in\",x.shape)\n",
    "        x = F.relu(self.cnn_out(x))\n",
    "\n",
    "        #x[x > 255.0] = 255.0\n",
    "        #x[x < 1.0] = 0\n",
    "\n",
    "        x = rearrange(x, 'b t c w h -> b t w h c')\n",
    "        return x\n",
    "\n",
    "runner = Runner(model_name='Resnet3D')\n",
    "runner.predict(checkpoint_dir='./checkpoints/Resnet3D.pk', mode='core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# Model 2 - SparseUNet\n",
    "import MinkowskiEngine as ME\n",
    "import MinkowskiEngine.MinkowskiFunctional as MF\n",
    "class SparseUNet(ME.MinkowskiNetwork):\n",
    "    def __init__(self, hs_block1=12, hs_block2=12, hs_block3=16, block3_tr=8, block2_tr=48):\n",
    "        in_nchannel, out_nchannel, D = 12, 6, 3\n",
    "        super(SparseUNet, self).__init__(D)\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolution(\n",
    "                in_channels=in_nchannel,\n",
    "                out_channels=hs_block1,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(hs_block1),\n",
    "        )\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolution(\n",
    "                in_channels=hs_block1,\n",
    "                out_channels=hs_block2,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(hs_block2),\n",
    "        )\n",
    "        self.block3 = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolution(\n",
    "                in_channels=hs_block2,\n",
    "                out_channels=hs_block3,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(hs_block3),\n",
    "        )\n",
    "        self.block3_tr = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolutionTranspose(\n",
    "                in_channels=hs_block3,\n",
    "                out_channels=block3_tr,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(block3_tr),\n",
    "        )\n",
    "        self.block2_tr = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolutionTranspose(\n",
    "                in_channels=hs_block2+block3_tr,\n",
    "                out_channels=block2_tr,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(block2_tr),\n",
    "        )\n",
    "        self.conv1_tr = ME.MinkowskiConvolution(\n",
    "            in_channels=hs_block1+block2_tr,\n",
    "            out_channels=out_nchannel,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            dimension=D,\n",
    "            expand_coordinates=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x to sparse tensor\n",
    "        x = ME.MinkowskiOps.to_sparse(x)\n",
    "\n",
    "        out_s1 = self.block1(x)\n",
    "        out = MF.relu(out_s1)\n",
    "\n",
    "        out_s2 = self.block2(out)\n",
    "        out = MF.relu(out_s2)\n",
    "\n",
    "        out_s4 = self.block3(out)\n",
    "        out = MF.relu(out_s4)\n",
    "\n",
    "        out = MF.relu(self.block3_tr(out))\n",
    "        out = ME.cat(out, out_s2)\n",
    "        out = MF.relu(self.block2_tr(out))\n",
    "        out = ME.cat(out, out_s1)\n",
    "\n",
    "        out = self.conv1_tr(out)\n",
    "\n",
    "        dense_output, min_coord, tensor_stride = out.dense()\n",
    "        missed_min_coordinate = np.array(dense_output.size()[-3:]) - np.array([495, 436, 8])\n",
    "        if missed_min_coordinate.sum() != 0:\n",
    "            dense_output, min_coord, tensor_stride = out.dense(\n",
    "            min_coordinate=torch.IntTensor(missed_min_coordinate)\n",
    "        )\n",
    "        return dense_output\n",
    "\n",
    "runner = Runner(model_name='SparseUNet')\n",
    "runner.predict(checkpoint_dir='./checkpoints/SparseUNet.pk', mode='extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
